{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nltk\n",
    "# %pip install pandas\n",
    "# %pip install scikit-learn\n",
    "# %pip install matplotlib\n",
    "# %pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\viswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\viswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\viswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\viswa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from string import punctuation\n",
    "from nltk import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_csv('dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "def data_cleanup(train_df):\n",
    "    train_df['text'] = train_df['text'].str.lower()\n",
    "    train_df['text'] = train_df['text'].str.strip()\n",
    "    train_df['text'] = train_df['text'].replace(to_replace ='http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', value = '', regex = True)\n",
    "    train_df['text'] = train_df['text'].replace(to_replace ='\\?*', value = '', regex = True)\n",
    "    train_df['text'] = train_df['text'].replace(to_replace ='(RT|rt)', value = '', regex = True)\n",
    "    train_df['text'] = train_df['text'].replace(to_replace ='@[a-z,_]*', value = '', regex = True)\n",
    "    train_df['text'] = train_df['text'].replace(to_replace ='([0-9]*:[0-9]*)', value = '', regex = True)\n",
    "    train_df['text'] = train_df['text'].replace(to_replace ='([0-9]*\\.[0-9]*)', value = '', regex = True)\n",
    "    train_df['text'] = train_df['text'].replace(to_replace ='(utc|gmt)', value = '', regex = True)\n",
    "    train_df['text'] = train_df['text'].replace(to_replace ='_[\\S]', value = '', regex = True)\n",
    "    train_df['text'] = train_df['text'].replace(to_replace ='&amp;?', value = 'and', regex = False)\n",
    "    train_df['text'] = train_df['text'].replace(to_replace ='&lt;', value = '<', regex = False)\n",
    "    train_df['text'] = train_df['text'].replace(to_replace ='&gt;', value = '>', regex = False)\n",
    "    train_df['text'] = train_df['text'].replace(to_replace ='[ ]{2, }', value = ' ', regex = True)\n",
    "    train_df['text'] = train_df['text'].replace(to_replace ='([^\\w\\d ]+)', value = '', regex = True)\n",
    "    return train_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# train_df = pd.read_csv('dataset/train.csv')\n",
    "input_df['text'] = data_cleanup(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this eahquake may ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the out of control wild fires in california ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m  5km s of volcano hawaii</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>police investigating after an ebike collided w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the latest more homes razed by nohern californ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     our deeds are the reason of this eahquake may ...       1  \n",
       "1                 forest fire near la ronge sask canada       1  \n",
       "2     all residents asked to shelter in place are be...       1  \n",
       "3     13000 people receive wildfires evacuation orde...       1  \n",
       "4     just got sent this photo from ruby alaska as s...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  two giant cranes holding a bridge collapse int...       1  \n",
       "7609    the out of control wild fires in california ...       1  \n",
       "7610                        m  5km s of volcano hawaii        1  \n",
       "7611  police investigating after an ebike collided w...       1  \n",
       "7612  the latest more homes razed by nohern californ...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Test Dataset split\n",
    "tweet_texts = input_df['text']\n",
    "class_labels = input_df['target']\n",
    "train_tweets, test_tweets, train_labels, test_labels = train_test_split(tweet_texts,class_labels,test_size=0.2, random_state=42, stratify=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat tweets and labels series from the split into dataframe\n",
    "train_cols = [pd.Series(train_tweets, name='text'), pd.Series(train_labels, name='labels')]\n",
    "train_df = pd.concat(train_cols, axis = 1)\n",
    "test_cols = [pd.Series(test_tweets, name='text'), pd.Series(test_labels, name='labels')]\n",
    "test_df = pd.concat(test_cols,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Preprocessor\n",
    "def preprocessing(text):\n",
    "   word_lemma = []\n",
    "   tweet_tokenize = TweetTokenizer()\n",
    "   tokens = tweet_tokenize.tokenize((text).lower())\n",
    "   tokens = [w for w in tokens if w not in punctuation and not w.isdigit() and not len(w) < 3]\n",
    "   stop_words = stopwords.words ('english')\n",
    "   tweet_without_stopwords = [t for t in tokens if t not in stop_words]\n",
    "   text = \" \".join (tweet_without_stopwords)\n",
    "   word_lemma = [WordNetLemmatizer().lemmatize(t) for t in tweet_tokenize.tokenize(text)]\n",
    "   pp_text = \" \".join (word_lemma)\n",
    "   return pp_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_score(actual_label : list, predicted_label : list):\n",
    "    '''Function to calculate the performance metric using sklearn.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    actual_label : list\n",
    "      Actual(Ground Truth) class label from the dataset.\n",
    "    predicted_label : pd.DataFrame\n",
    "      Class label predicted by the model\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    f1_score : float\n",
    "    accuracy : float\n",
    "    precision : float\n",
    "    recall : float\n",
    "    AUROC : float\n",
    "    '''\n",
    "    precision = metrics.precision_score(actual_label, predicted_label, pos_label=1)\n",
    "    recall = metrics.recall_score(actual_label, predicted_label,pos_label=1)\n",
    "    AUROC = metrics.roc_auc_score(actual_label, predicted_label)\n",
    "    accuracy = metrics.accuracy_score(actual_label, predicted_label)\n",
    "    f1_score = metrics.f1_score(actual_label, predicted_label,pos_label=1)\n",
    "    confusion_mat = metrics.confusion_matrix(actual_label, predicted_label)\n",
    "    metrics_list = [f1_score, accuracy, precision, recall, AUROC]\n",
    "    metrics_list = pd.DataFrame(metrics_list).T\n",
    "    metrics_df = metrics_list.rename(columns={0:'F1',1:'Accuracy',2:'Precision',3:'Recall',4:'AUROC'})\n",
    "    return metrics_df, confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_mat, model_name):\n",
    "    _, cm_ax = plt.subplots(facecolor='#212936')\n",
    "    cm_plot = ConfusionMatrixDisplay(confusion_matrix=confusion_mat,display_labels=['Not Disaster','Disaster'])\n",
    "    title = model_name + \" Confusion Matrix\"\n",
    "    cm_plot.plot(cmap=plt.cm.Greens, ax=cm_ax)\n",
    "    plt.title(title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_mat, theme, model):\n",
    "    if theme == 'dark':\n",
    "        plt.rcParams['text.color'] = 'white'\n",
    "        plt.rcParams['axes.labelcolor'] = 'white'\n",
    "        plt.rcParams['xtick.color'] = 'white'\n",
    "        plt.rcParams['ytick.color'] = 'white'\n",
    "        cm_fig, cm_ax = plt.subplots(facecolor='#212936', figsize=(6,4))\n",
    "    elif theme == 'light':\n",
    "        plt.rcParams['text.color'] = 'black'\n",
    "        plt.rcParams['axes.labelcolor'] = 'black'\n",
    "        plt.rcParams['xtick.color'] = 'black'\n",
    "        plt.rcParams['ytick.color'] = 'black'\n",
    "        cm_fig, cm_ax = plt.subplots(facecolor='#FFFFFF', figsize=(6,4))\n",
    "    cm_plot = ConfusionMatrixDisplay(confusion_matrix=confusion_mat,display_labels=['Not Disaster','Disaster'])\n",
    "    title = model + \" Confusion Matrix\"\n",
    "    cm_plot.plot(cmap=plt.cm.Greens, ax=cm_ax)\n",
    "    plt.title(title)\n",
    "    cm_fig.savefig(f'results/images/confusion/{model}_{theme}.png', bbox_inches='tight')\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable definitions\n",
    " - train_tweets - Preprocessed tweets for training\n",
    " - test_tweets - Preprocessed tweets for testing\n",
    " - train_labels - class label for training tweets\n",
    " - test_labels - class label for test tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "1. Implement traditional model(MultinomialNB, LogisticRegression, SVC, KNeighborsClassifier) from sklearn\n",
    "2. Train and test the default model without tuning hyperparameter values\n",
    "3. Use grid search(GridSearchCV) from sklearn to identify best values for hyperparameters\n",
    "4. Train the model with best hypermeter values and test it on test set(test_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(preprocessor=preprocessing,ngram_range = (1,2))\n",
    "vectors_train = vectorizer.fit_transform(train_df['text'])\n",
    "vectors_test = vectorizer.transform(test_df['text'])\n",
    "train_labels = train_df['labels']\n",
    "test_labels = test_df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_grid_search(model, param_grid, cv, scoring, train_tweet, train_label):\n",
    "  '''Function to perform grid search.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Object\n",
    "    norm : str\n",
    "    param_grid : list\n",
    "    cv : int\n",
    "    scoring : str\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    grid_search : Object\n",
    "    '''\n",
    "  grid_search = GridSearchCV(model, param_grid, cv=cv, scoring=scoring, n_jobs=-1, return_train_score=True, error_score = True)\n",
    "  grid_search.fit(train_tweet, train_label)\n",
    "  return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_perf_score(models_list, perf_score_list):\n",
    "  '''Function to consolidate the performance metrics of all the models(KNeighborsClassifier, RandomForestClassifier, LogisticRegression, MLPClassifier) \n",
    "  and return a pd.DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    models_list : list\n",
    "      List of models.\n",
    "    perf_score_list : list\n",
    "      List of performance metrics data frame from various models.\n",
    "      \n",
    "    Return\n",
    "    ------\n",
    "    consolidated_metrics_df : pd.DataFrame\n",
    "    '''\n",
    "  \n",
    "  consolidated_perf_score_df = pd.concat(perf_score_list)\n",
    "  consolidated_perf_score_df = consolidated_perf_score_df.rename(columns={0:'F1',1:'Accuracy',2:'Precision',3:'Recall'})\n",
    "  consolidated_perf_score_df.insert(0,'Model',models_list)\n",
    "  return consolidated_perf_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_trad_models():\n",
    "    '''Function to initialize the traditional models from sklearn.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    nb : Object\n",
    "    knc : Object\n",
    "    lr : Object\n",
    "    svc : Object\n",
    "    '''\n",
    "    nb = MultinomialNB()\n",
    "    knc = KNeighborsClassifier()\n",
    "    lr = LogisticRegression()\n",
    "    svc = SVC()\n",
    "    return nb, knc,lr, svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb, knc, lr, svc = initialize_trad_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "param_grid = {\n",
    "      'alpha': (0.01,0.2,0.4,1.0),\n",
    "      'fit_prior': (True,False)}\n",
    "nb_gs = cv_grid_search(nb, param_grid, 10, 'f1', vectors_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'n_neighbors': [3, 5, 10, 12],\n",
    "               'p': [1, 2],\n",
    "               'weights':['uniform', 'distance'],\n",
    "               'algorithm': ['auto', 'brute']}]\n",
    "knc_gs = cv_grid_search(knc, param_grid, 10, 'f1', vectors_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'penalty': ['l2'],\n",
    "     'tol': [1e-3, 1e-4],\n",
    "     'solver':['lbfgs', 'liblinear'],\n",
    "     'max_iter': [1000, 5000, 10000],\n",
    "     'random_state': [42]}\n",
    "  ]\n",
    "lr_gs = cv_grid_search(lr, param_grid, 10, 'f1', vectors_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'kernel': ['poly', 'sigmoid', 'rbf'],\n",
    "     'gamma' : ['scale', 'auto'],\n",
    "     'random_state': [42]}\n",
    "  ]\n",
    "svc_gs = cv_grid_search(svc, param_grid, 10, 'f1', vectors_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nb, best_knc, best_lr, best_svc = initialize_trad_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the best parameter values for each model from grid search for the hyperparameters \n",
    "best_nb.set_params(**nb_gs.best_params_)\n",
    "best_knc.set_params(**knc_gs.best_params_)\n",
    "best_lr.set_params(**lr_gs.best_params_)\n",
    "best_svc.set_params(**svc_gs.best_params_)\n",
    "\n",
    "#Train the each model with the best parameters\n",
    "best_nb.fit(vectors_train,train_labels)\n",
    "best_knc.fit(vectors_train,train_labels)\n",
    "best_lr.fit(vectors_train,train_labels)\n",
    "best_svc.fit(vectors_train,train_labels)\n",
    "\n",
    "#Predict the labels on test dataset using the trained models\n",
    "nb_predict = best_nb.predict(vectors_test)\n",
    "knc_predict = best_knc.predict(vectors_test)\n",
    "lr_predict = best_lr.predict(vectors_test)\n",
    "svc_predict = best_svc.predict(vectors_test)\n",
    "nb_predicted_labels = np.array(nb_predict, dtype = int)\n",
    "knc_predicted_labels = np.array(knc_predict, dtype = int)\n",
    "lr_predictted_labels = np.array(lr_predict, dtype = int)\n",
    "svc_predicted_labels = np.array(svc_predict, dtype = int)\n",
    "actual_labels = np.array(test_labels, dtype = int)\n",
    "\n",
    "#Calculate the performance metrics based on the predicted labels and actual labels in test dataset\n",
    "nb_perf_scores, nb_cm = get_performance_score(nb_predicted_labels, actual_labels)\n",
    "knc_perf_scores, knc_cm = get_performance_score(knc_predicted_labels, actual_labels)\n",
    "lr_perf_scores, lr_cm = get_performance_score(lr_predictted_labels, actual_labels)\n",
    "svc_perf_scores, svc_cm = get_performance_score(svc_predicted_labels, actual_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mats = {\n",
    "    'Naive Bayes': nb_cm,\n",
    "    'K-Nearest Neighbor': knc_cm,\n",
    "    'Logistic Regression': lr_cm,\n",
    "    'SVM': svc_cm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidate_perf_score(['nb', 'knc', 'lr', 'svc'], [nb_perf_scores, knc_perf_scores, lr_perf_scores, svc_perf_scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install torch\n",
    "# !pip install datasets\n",
    "# !pip install evaluate\n",
    "# !pip install numpy\n",
    "# !pip install accelerate\n",
    "# !pip install emoji==0.6.0\n",
    "# !pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertweetTokenizer\n",
    "from transformers import AlbertTokenizer, AlbertModel\n",
    "from transformers import AutoModel\n",
    "from transformers import DataCollatorWithPadding\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\n",
    "from transformers import AutoConfig\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in input_df.iterrows():\n",
    "        text = row['text']\n",
    "        pp_text = preprocessing(text)\n",
    "        input_df.at[index, 'text'] = pp_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Test Dataset split\n",
    "tweet_texts = input_df['text']\n",
    "class_labels = input_df['target']\n",
    "train_tweets, test_tweets, train_labels, test_labels = train_test_split(tweet_texts,class_labels,test_size=0.2, random_state=42, stratify=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##raining and Dev Dataset split\n",
    "tweet_texts = train_tweets\n",
    "class_labels = train_labels\n",
    "train_tweets, dev_tweets, train_labels, dev_labels = train_test_split(tweet_texts,class_labels,test_size=0.2, random_state=42, stratify=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat tweets and labels series from the split into dataframe\n",
    "train_cols = [pd.Series(train_tweets, name='text'), pd.Series(train_labels, name='labels')]\n",
    "train_df = pd.concat(train_cols, axis = 1)\n",
    "dev_cols = [pd.Series(dev_tweets, name='text'), pd.Series(dev_labels, name='labels')]\n",
    "dev_df = pd.concat(dev_cols, axis = 1)\n",
    "test_cols = [pd.Series(test_tweets, name='text'), pd.Series(test_labels, name='labels')]\n",
    "test_df = pd.concat(test_cols,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define constants for BERTweet model\n",
    "model_name = \"model/bertweet/v1\"\n",
    "max_length = 32\n",
    "trucate = True\n",
    "padding='max_length'\n",
    "batch_size = 32\n",
    "# mps_device = torch.device(\"mps\")\n",
    "# cuda_device = torch.device(\"cuda\")\n",
    "id2text = {0: \"not_disaster\", 1: \"disaster\"}\n",
    "text2id = {\"not_disaster\": 0, \"disaster\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize tokenizer, data_collector and classifier for BERTweet\n",
    "tokenizer = BertweetTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "classifier = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, id2label=id2text, label2id=text2id)\n",
    "# classifier = classifier.to(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(input):\n",
    "     token_ids_dict = tokenizer.encode_plus(input['text'], add_special_tokens = True, padding=padding, max_length=max_length, truncation=trucate,return_attention_mask = True)\n",
    "     token_ids_dict['label'] = input['labels']\n",
    "     return token_ids_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4872/4872 [00:01<00:00, 3712.26 examples/s]\n",
      "Map: 100%|██████████| 1218/1218 [00:00<00:00, 3333.59 examples/s]\n",
      "Map: 100%|██████████| 1523/1523 [00:00<00:00, 3459.16 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#Convert the input text into token_ids, attention_mask and token_type_ids dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(dev_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "train_map = train_dataset.map(preprocessor)\n",
    "dev_map = eval_dataset.map(preprocessor)\n",
    "test_map = test_dataset.map(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f1(labels):\n",
    "    f1 = evaluate.load(\"f1\")\n",
    "    predicted, actual = labels\n",
    "    predicted = np.argmax(predicted, axis=1)\n",
    "    return f1.compute(predictions=predicted, references=actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize Trainer and Training Arguments for finetuning BERTweet\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"trainer_cache\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model = 'f1',\n",
    "    greater_is_better=True,\n",
    "    num_train_epochs=8,\n",
    "    learning_rate = 1e-5,\n",
    "    adam_epsilon = 1e-5,\n",
    "    weight_decay = 1e-5,\n",
    "    adafactor = False,\n",
    "    # use_mps_device=False\n",
    "\n",
    ")\n",
    "\n",
    "bt_trainer = Trainer(\n",
    "    model=classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=train_map,\n",
    "    eval_dataset=dev_map,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=calculate_f1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finetune BERTweet\n",
    "# bt_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:06<00:00, 29.98it/s]\n"
     ]
    }
   ],
   "source": [
    "actual_label = test_df['labels']\n",
    "predictions_prob = bt_trainer.predict(test_map)\n",
    "predictions =  predictions_prob.predictions\n",
    "predictions = np.argmax(predictions,axis=1)\n",
    "predicted_lables = np.array(predictions, dtype = int)\n",
    "actual_labels = np.array(actual_label, dtype = int)\n",
    "bt_metrics_df, bt_confusion_mat = get_performance_score(actual_labels, predicted_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         F1  Accuracy  Precision    Recall     AUROC\n",
       " 0  0.808411  0.838477    0.82381  0.793578  0.832922,\n",
       " array([[758, 111],\n",
       "        [135, 519]], dtype=int64))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt_metrics_df, bt_confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mats['BERTweet'] = bt_confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(bt_confusion_mat, 'light', 'BERTweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bt_trainer.save_model(output_dir = 'model/bertweet/v1/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"FacebookAI/xlm-roberta-base\"\n",
    "model_name = 'model/roberta/v1'\n",
    "max_length = 32\n",
    "trucate = True\n",
    "padding='max_length'\n",
    "id2text = {0: \"not_disaster\", 1: \"disaster\"}\n",
    "text2id = {\"not_disaster\": 0, \"disaster\": 1}\n",
    "# classifier = classifier.to(mps_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "classifier = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, id2label=id2text, label2id=text2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(input):\n",
    "     token_ids_dict = tokenizer.encode_plus(input['text'], add_special_tokens = True, padding=padding, max_length=max_length, truncation=trucate,return_attention_mask = True)\n",
    "     token_ids_dict['label'] = input['labels']\n",
    "     return token_ids_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4872/4872 [00:01<00:00, 4843.01 examples/s]\n",
      "Map: 100%|██████████| 1218/1218 [00:00<00:00, 5021.17 examples/s]\n",
      "Map: 100%|██████████| 1523/1523 [00:00<00:00, 5059.08 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#Convert the input text into token_ids, attention_mask and token_type_ids dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset = Dataset.from_pandas(dev_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "train_map = train_dataset.map(preprocessor)\n",
    "dev_map = eval_dataset.map(preprocessor)\n",
    "test_map = test_dataset.map(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"trainer_cache\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model = 'f1',\n",
    "    greater_is_better=True,\n",
    "    num_train_epochs=8,\n",
    "    learning_rate = 1e-5,\n",
    "    adam_epsilon = 1e-5,\n",
    "    weight_decay = 1e-5,\n",
    "    adafactor = False,\n",
    "    use_mps_device=False\n",
    "\n",
    ")\n",
    "\n",
    "rb_trainer = Trainer(\n",
    "    model=classifier,\n",
    "    args=training_args,\n",
    "    train_dataset=train_map,\n",
    "    eval_dataset=dev_map,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=calculate_f1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rb_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:06<00:00, 30.38it/s]\n"
     ]
    }
   ],
   "source": [
    "actual_label = test_df['labels']\n",
    "predictions_prob = rb_trainer.predict(test_map)\n",
    "predictions =  predictions_prob.predictions\n",
    "predictions = np.argmax(predictions,axis=1)\n",
    "predicted_lables = np.array(predictions, dtype = int)\n",
    "actual_labels = np.array(actual_label, dtype = int)\n",
    "rb_metrics_df, rb_confusion_mat = get_performance_score(actual_labels, predicted_lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rb_trainer.save_model(output_dir = 'model/roberta/v1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         F1  Accuracy  Precision    Recall     AUROC\n",
       " 0  0.789713  0.817466   0.781437  0.798165  0.815078,\n",
       " array([[723, 146],\n",
       "        [132, 522]], dtype=int64))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb_metrics_df, rb_confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mats['RoBERTa'] = rb_confusion_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(rb_confusion_mat, 'dark', 'RoBERTa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.766400</td>\n",
       "      <td>0.808273</td>\n",
       "      <td>0.732416</td>\n",
       "      <td>0.803691</td>\n",
       "      <td>0.807455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.621535</td>\n",
       "      <td>0.533815</td>\n",
       "      <td>0.891437</td>\n",
       "      <td>0.477087</td>\n",
       "      <td>0.620603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.773289</td>\n",
       "      <td>0.819435</td>\n",
       "      <td>0.717125</td>\n",
       "      <td>0.838998</td>\n",
       "      <td>0.823545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.761578</td>\n",
       "      <td>0.817466</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.867188</td>\n",
       "      <td>0.829736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERTweet</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.838477</td>\n",
       "      <td>0.823810</td>\n",
       "      <td>0.793578</td>\n",
       "      <td>0.832922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RoBERTa</td>\n",
       "      <td>0.789713</td>\n",
       "      <td>0.817466</td>\n",
       "      <td>0.781437</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.815078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model        F1  Accuracy  Precision    Recall     AUROC\n",
       "0        NB  0.766400  0.808273   0.732416  0.803691  0.807455\n",
       "0       KNN  0.621535  0.533815   0.891437  0.477087  0.620603\n",
       "0        LR  0.773289  0.819435   0.717125  0.838998  0.823545\n",
       "0       SVM  0.761578  0.817466   0.678899  0.867188  0.829736\n",
       "0  BERTweet  0.808411  0.838477   0.823810  0.793578  0.832922\n",
       "0   RoBERTa  0.789713  0.817466   0.781437  0.798165  0.815078"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidate_perf_score(['NB', 'KNN', 'LR', 'SVM', 'BERTweet', 'RoBERTa'], [nb_perf_scores, knc_perf_scores, lr_perf_scores, svc_perf_scores, bt_metrics_df, rb_metrics_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix(lr_cm, 'light', 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices for all the models except CNN and RNN\n",
    "def plot_confusion_mats(confusion_mats):\n",
    "    themes = ['light', 'dark']\n",
    "    for theme in themes:\n",
    "        for name, confusion_mat in confusion_mats.items():\n",
    "            plot_confusion_matrix(confusion_mat, theme, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mats(confusion_mats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_preprocessor(input):\n",
    "     token_ids_dict = tokenizer.encode_plus(input['text'], add_special_tokens = True, padding=padding, max_length=max_length, truncation=trucate,return_attention_mask = True)\n",
    "     return token_ids_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB</th>\n",
       "      <th>KNC</th>\n",
       "      <th>LR</th>\n",
       "      <th>SVC</th>\n",
       "      <th>BERTweet</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>RNN</th>\n",
       "      <th>CNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUROC</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             NB   KNC    LR   SVC  BERTweet  RoBERTa   RNN   CNN\n",
       "Accuracy   0.81  0.53  0.82  0.82      0.84     0.82  0.81  0.80\n",
       "Precision  0.73  0.89  0.72  0.68      0.82     0.78  0.84  0.85\n",
       "Recall     0.80  0.48  0.84  0.87      0.79     0.80  0.69  0.66\n",
       "F1         0.77  0.62  0.77  0.76      0.81     0.79  0.76  0.74\n",
       "AUROC      0.81  0.62  0.82  0.83      0.83     0.82  0.80  0.79"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_results_df = pd.read_csv('results/csv/performance_results.csv')\n",
    "perf_results_df = perf_results_df.T\n",
    "perf_results_df.columns=['NB', 'KNC', 'LR', 'SVC', 'BERTweet', 'RoBERTa', 'RNN', 'CNN']\n",
    "perf_results_df=perf_results_df[1:]\n",
    "perf_results_df = perf_results_df.astype('float32')\n",
    "perf_results_df = perf_results_df.round(2)\n",
    "# perf_results_df.insert(0, 'Metrics', perf_results_df.index)\n",
    "# perf_results_df.index = list(range(0, len(perf_results_df)))\n",
    "perf_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_plots(perf_results_df):\n",
    "    model_dict = {'NB':'Naive Bayes', 'LR':'Logistic Regression','SVC':'SVM','KNC':'K-Nearest Neighbor',\n",
    "                'CNN':'CNN','RNN':'RNN',\n",
    "                'BERTweet':'BERTweet','RoBERTa':'RoBERTa'}\n",
    "    themes = ['light', 'dark']\n",
    "    for theme in themes:\n",
    "        for shortName, longName in model_dict.items():\n",
    "            if theme == 'light':\n",
    "                plt.rcParams['text.color'] = 'black'\n",
    "                plt.rcParams['axes.labelcolor'] = 'black'\n",
    "                plt.rcParams['xtick.color'] = 'black'\n",
    "                plt.rcParams['ytick.color'] = 'black'\n",
    "                plt.rcParams['axes.edgecolor'] = 'black'\n",
    "                _, bar_ax = plt.subplots(facecolor='#FFFFFF')\n",
    "                bar_plot = perf_results_df[shortName].plot(figsize=(8,4), title=f\"{longName} Performance Metrics\", kind='bar', ax = bar_ax)\n",
    "                bar_plot.set_facecolor('#FFFFFF')\n",
    "            elif theme == 'dark':\n",
    "                plt.rcParams['text.color'] = 'white'\n",
    "                plt.rcParams['axes.labelcolor'] = 'white'\n",
    "                plt.rcParams['xtick.color'] = 'white'\n",
    "                plt.rcParams['ytick.color'] = 'white'\n",
    "                plt.rcParams['axes.edgecolor'] = '#ffffff'\n",
    "                _, bar_ax = plt.subplots(facecolor='#212936')\n",
    "                bar_plot = perf_results_df[shortName].plot(figsize=(8,4), title=f\"{longName} Performance Metrics\", kind='bar', ax=bar_ax)\n",
    "                bar_plot.set_facecolor('#212936')\n",
    "                bar_plot.spines\n",
    "            bar_labels = bar_plot.bar(perf_results_df.index, perf_results_df[shortName], color = 'g', width=0.5)\n",
    "            bar_plot.bar_label(bar_labels, label_type='edge')\n",
    "            bar_plot.set_ylim([0, 1])\n",
    "            plt.savefig(f'results/images/performance/{longName}_{theme}.png', bbox_inches='tight')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bar_plots(perf_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_file_predict(path):\n",
    "    prod_input_df = pd.read_csv(path)\n",
    "    prod_input_df['text'] = data_cleanup(prod_input_df)\n",
    "    prod_input_df['text'] = prod_input_df['text'].apply(preprocessing)\n",
    "    prod_test_dataset = Dataset.from_pandas(prod_input_df)\n",
    "    prod_test_dataset_map = prod_test_dataset.map(prod_preprocessor)\n",
    "    prod_predictions_prob = bt_trainer.predict(prod_test_dataset_map)\n",
    "    prod_predictions =  prod_predictions_prob.predictions\n",
    "    prod_predictions = np.argmax(prod_predictions,axis=1)\n",
    "    prod_predicted_lables = np.array(prod_predictions, dtype = int)\n",
    "    prod_output_df = pd.DataFrame(data=prod_input_df['text'], columns=['text'])\n",
    "    prod_output_df['label'] = pd.Series(prod_predicted_lables)\n",
    "    output_map = {\n",
    "        0: 'Not Disaster',\n",
    "        1: 'Disaster'\n",
    "    }\n",
    "    prod_output_df['label'] = prod_output_df['label'].map(output_map)\n",
    "    return prod_output_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_text_predict(text):\n",
    "    text_dict = {}\n",
    "    text_dict['text'] = text\n",
    "    prod_input_df = pd.DataFrame(text_dict.values(), columns=['text'])\n",
    "    prod_input_df['text'] = data_cleanup(prod_input_df)\n",
    "    prod_input_df['text'] = prod_input_df['text'].apply(preprocessing)\n",
    "    prod_test_dataset = Dataset.from_pandas(prod_input_df)\n",
    "    prod_test_dataset_map = prod_test_dataset.map(prod_preprocessor)\n",
    "    prod_predictions_prob = bt_trainer.predict(prod_test_dataset_map)\n",
    "    prod_predictions =  prod_predictions_prob.predictions\n",
    "    prod_predictions = np.argmax(prod_predictions,axis=1)\n",
    "    prod_predicted_lables = np.array(prod_predictions, dtype = int)\n",
    "    prod_output_df = pd.DataFrame(data=prod_input_df['text'], columns=['text'])\n",
    "    prod_output_df['label'] = pd.Series(prod_predicted_lables)\n",
    "    output_map = {\n",
    "        0: 'Not Disaster',\n",
    "        1: 'Disaster'\n",
    "    }\n",
    "    prod_output_df['label'] = prod_output_df['label'].map(output_map)\n",
    "    return prod_output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(metrics_input,model_input):\n",
    "    theme = 'dark'\n",
    "    metric_dict = {'Performance Metrics':'./results/images/bar/', \n",
    "               'Confusion Matrix':'./results/images/confusion/'}\n",
    "    model_dict = {'NB':'Naive Bayes', 'LR':'Logistic Regression','SVM':'SVM','KNN':'K-Nearest Neighbor',\n",
    "              'CNN':'CNN','RNN':'RNN',\n",
    "              'BERTweet':'BERTweet','RoBERTa':'RoBERTa'}\n",
    "    base_dir = metric_dict[metrics_input]\n",
    "    filename = model_dict[model_input]\n",
    "    file_path = base_dir+filename+'_'+theme+'.png'\n",
    "    return file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 105.17 examples/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 914.79it/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 331.41 examples/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Map: 100%|██████████| 3263/3263 [00:00<00:00, 4242.71 examples/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\gradio\\queueing.py\", line 527, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\gradio\\route_utils.py\", line 261, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\gradio\\blocks.py\", line 1788, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\gradio\\blocks.py\", line 1340, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2144, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\gradio\\utils.py\", line 759, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\viswa\\AppData\\Local\\Temp\\ipykernel_12072\\852238599.py\", line 8, in file_predict\n",
      "    output = prod_file_predict(input)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\viswa\\AppData\\Local\\Temp\\ipykernel_12072\\2186257198.py\", line 7, in prod_file_predict\n",
      "    prod_predictions_prob = bt_trainer.predict(prod_test_dataset_map)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\transformers\\trainer.py\", line 3543, in predict\n",
      "    output = eval_loop(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\transformers\\trainer.py\", line 3666, in evaluation_loop\n",
      "    logits = self.accelerator.pad_across_processes(logits, dim=1, pad_index=-100)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\accelerate\\accelerator.py\", line 2350, in pad_across_processes\n",
      "    return pad_across_processes(tensor, dim=dim, pad_index=pad_index, pad_first=pad_first)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\accelerate\\utils\\operations.py\", line 417, in wrapper\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\accelerate\\utils\\operations.py\", line 684, in pad_across_processes\n",
      "    return recursively_apply(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\accelerate\\utils\\operations.py\", line 126, in recursively_apply\n",
      "    return func(data, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\viswa\\miniconda3\\envs\\mlproject\\Lib\\site-packages\\accelerate\\utils\\operations.py\", line 664, in _pad_across_processes\n",
      "    size = torch.tensor(tensor.shape, device=tensor.device)[None]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def text_predict(input):\n",
    "    output = prod_text_predict(input)\n",
    "    return output.iloc[0]['label']\n",
    "\n",
    "def file_predict(input):\n",
    "    output = prod_file_predict(input)\n",
    "    return output\n",
    "\n",
    "def model_performance(metrics_input,model_input):\n",
    "    file_path = get_file_name(metrics_input,model_input)\n",
    "    output_plot = gr.Image(file_path, height = 600, width = 600)\n",
    "    return output_plot\n",
    "\n",
    "with gr.Blocks() as gui_demo:\n",
    "    gr.Markdown(\"Automated Classification of Disaster-Related Tweets\")\n",
    "    with gr.Tab(\"Text\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                text_input = gr.Textbox(label= \"Input Tweet\")\n",
    "                text_button = gr.Button(\"Predict\")\n",
    "            with gr.Column():\n",
    "                text_output = gr.Textbox(label = \"Prediction\")\n",
    "        \n",
    "    with gr.Tab(\"File\"):\n",
    "        # with gr.Row():\n",
    "        file_input = gr.File(label= \"Input File (as .csv)\")\n",
    "        file_output = gr.DataFrame(label = \"Prediction\")\n",
    "        file_button = gr.Button(\"Predict\")\n",
    "    with gr.Tab(\"API\"):\n",
    "        with gr.Row():\n",
    "            api_input = gr.Textbox(label= \"API Endpoint\")\n",
    "        api_button = gr.Button(\"Predict\")\n",
    "    with gr.Tab(\"Model Performance\"):\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                metric_choices = ['Performance Metrics', 'Confusion Matrix']\n",
    "                metrics_input = gr.Radio(choices = metric_choices, \n",
    "                                        value = 'Performance Metrics', \n",
    "                                        type = 'value',\n",
    "                                        show_label = True, \n",
    "                                        interactive = True,\n",
    "                                        label= \"Select metric\")\n",
    "                model_choices = ['NB', 'LR', 'SVM', 'KNN', 'CNN', 'RNN', 'BERTweet', 'RoBERTa', 'All' ]\n",
    "                model_input = gr.Radio(choices = model_choices, \n",
    "                                        value = 'NB', \n",
    "                                        type = 'value',\n",
    "                                        show_label = True, \n",
    "                                        interactive = True,\n",
    "                                        label= \"Select model\")\n",
    "                model_perf_button = gr.Button(\"View Results\")\n",
    "            with gr.Column():\n",
    "                model_output = gr.Image()\n",
    "        \n",
    "\n",
    "    text_button.click(text_predict, inputs=text_input, outputs=text_output)\n",
    "    file_button.click(file_predict, inputs=file_input, outputs=file_output)\n",
    "    model_perf_button.click(model_performance, inputs=[metrics_input,model_input] , outputs=model_output)\n",
    "\n",
    "# gui_demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "gui_demo.close()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detect-disaster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
